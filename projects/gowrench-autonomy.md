---
layout: default
permalink: /projects/gowrench-autonomy/
---

# ðŸ” Autonomous Vehicle Perception System (GoWrench Project)

A Masterâ€™s-level engineering project focused on solving real-world mobility challenges using an autonomous off-road robot. Developed in collaboration with GoWrench Inc., this initiative integrates GNSS, ROS, and YOLO-based vision systems to support Level 4 autonomous navigation.

---

## Overview

In collaboration with GoWrench Inc., we developed a **Level 4 autonomous off-road navigation system** using ROS, GNSS localization, and real-time camera-based segmentation. The system enables robots to follow preplanned routes while navigating around obstacles with high precision using Jetson Orin and Oak-D cameras.

The project used the Husky UGV as a research platform and simulated GNSS and IMU data to validate algorithms before real-world deployment. Visual perception was enhanced using YOLOv8 and YOLOP models, which provided both semantic segmentation and depth estimation via stereo vision.

ðŸ“„ [**Download Final Report (PDF)**](/sebastianriveraportfolio/docs/pdf/SEP_799_Final_Report_GoWrench.pdf)  
ðŸ–¼ï¸ [**Download Project Poster (PDF)**](/sebastianriveraportfolio/docs/pdf/SEP_799_Final_Digital_Project_Poster.pdf)


---

## Key Features

- ðŸ“ GNSS-based localization fused with IMU using an Extended Kalman Filter (EKF)  
- ðŸ§  YOLOv8 with depth perception for real-time road and pedestrian detection  
- ðŸ—ºï¸ Google Maps API integration for real-world route planning  
- ðŸ’» Dockerized deployment on NVIDIA Jetson Orin with ROS and DepthAI  
- ðŸ“¡ Waypoint self-navigation tested in RViz and simulated environments  

---

# ðŸ› ï¸ Engineering Breakdown

### ðŸ§­ Navigation Stack
- Integrated ROS `move_base`, `navfn`, and `dwa_local_planner`  
- Simulated GNSS and IMU data using custom ROS nodes  
- Used static transforms and costmaps to test paths indoors  
- Tested route generation using real-world waypoints from Google Maps API

### ðŸ§  Visual Perception
- Oak-D cameras running YOLOv8 in Docker with DepthAI integration  
- Real-time XYZ depth estimation and road segmentation using YOLOP  
- Simulated driving scenarios using X, Y, Z bounding box calibration  
- Accuracy tested under varying distance thresholds (2â€“6% depth error)

---

## ðŸ“Š Testing & Validation

- Validated simulated paths in RViz and Google Earth  
- Achieved successful fusion of GNSS + IMU with reliable localization output  
- ROS architecture validated using bag files and static transforms  
- Achieved consistent XYZ output from stereo depth vision under test conditions

---

## ðŸ’¡ Skills Applied

- Autonomous navigation in ROS (NavStack, costmaps, launch files)  
- Real-time segmentation and object detection (YOLOv8, YOLOP)  
- Depth sensing with Oak-D stereo cameras  
- Dockerized AI deployment on Jetson Orin  
- GNSS + IMU data fusion and localization (EKF)

---

## ðŸ”® Future Enhancements

- Merge YOLOP + YOLOv8 + depth data into a unified inference pipeline  
- Integrate live sensor feedback for real-time obstacle avoidance  
- Expand GNSS + move_base integration for fully dynamic self-navigation  
- Real-world deployment and fine-tuning of Z-axis predictions while in motion

---

### ðŸ“ Project Year: 2024  
### ðŸ‘¥ Team: Haocun (Matt) Jing & Sebastian Rivera  
### ðŸ§‘â€ðŸ« Faculty Lead: Dr. Moein Mehrtash  
### ðŸ¤ Partner: GoWrench Inc.  

---

> _"From simulated transforms to real-world path planning, this project demonstrated how ROS-based systems can drive robust, self-navigating autonomous platforms in partnership with industry."_


